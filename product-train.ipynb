{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"product-train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOj7ykilm3RE+EVh/R/p8gW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"L1_-_bwV9csl","colab_type":"code","outputId":"0f36d9c7-e923-4a0c-b62b-38f5abaadb40","executionInfo":{"status":"ok","timestamp":1591599046505,"user_tz":-420,"elapsed":17577,"user":{"displayName":"Hoang Manh TIEN","photoUrl":"","userId":"14223269599878818311"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"suLlryTk8tFt","colab_type":"code","outputId":"a147129f-81fd-4f78-fb84-15ea69582ee8","executionInfo":{"status":"ok","timestamp":1591601564472,"user_tz":-420,"elapsed":900,"user":{"displayName":"Hoang Manh TIEN","photoUrl":"","userId":"14223269599878818311"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /gdrive/My Drive/efficientnet"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/gdrive/My Drive/efficientnet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_wVXGqFSLb8f","colab_type":"code","colab":{}},"source":["!unzip data3.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mO1NeAy90g8","colab_type":"code","colab":{}},"source":["from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7LnXuOEiAb_v","colab_type":"code","outputId":"cbe3450a-e2f8-4735-dc8c-afffef3d28cf","executionInfo":{"status":"ok","timestamp":1591604653508,"user_tz":-420,"elapsed":3362,"user":{"displayName":"Hoang Manh TIEN","photoUrl":"","userId":"14223269599878818311"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["\n","# create the base pre-trained model\n","base_model = MobileNetV2(weights='imagenet',input_shape=(224,224,3), include_top=False)\n","\n","# add a global spatial average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","# let's add a fully-connected layer\n","# x = Dense(1024, activation='relu')(x)\n","#x = Dropout(0.5)(x)\n","x = Dense(128,activation='relu')(x)\n","x = Dropout(0.3)(x)\n","# and a logistic layer -- let's say we have 3 classes\n","predictions = Dense(4, activation='softmax')(x)\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)\n","print(len(base_model.layers))\n","# first: train only the top layers (which were randomly initialized)\n","# i.e. freeze all convolutional InceptionV3 layers\n","for layer in base_model.layers[:100]:\n","    layer.trainable = False\n","\n","# compile the model (should be done *after* setting layers to non-trainable)\n","lr_schedule = ExponentialDecay(\n","    initial_learning_rate=0.001,\n","    decay_steps=500,\n","    decay_rate=0.9)\n","optimizer = SGD(learning_rate=lr_schedule, momentum=0.9)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","\n","\n","model_file = \"models/Epoch{epoch:02d}-loss{loss:.3f}-val{val_loss:.5f}.h5\"\n","checkpoint = ModelCheckpoint(model_file, monitor='val_loss',verbose=1, save_best_only=True,mode='min')\n","callbacks_list = [checkpoint]\n","\n","# model.summary()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9412608/9406464 [==============================] - 0s 0us/step\n","155\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"onH7rx6RSAMx","colab_type":"code","outputId":"c09bd8c7-cede-44d9-b43f-74b962e4b55f","executionInfo":{"status":"ok","timestamp":1591606576755,"user_tz":-420,"elapsed":875,"user":{"displayName":"Hoang Manh TIEN","photoUrl":"","userId":"14223269599878818311"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["train_datagen = ImageDataGenerator(\n","        # rescale=1./255,\n","        shear_range=1,\n","        width_shift_range=10,\n","        rotation_range = 1,\n","        brightness_range=[0,2],\n","        validation_split=0.2,\n","        horizontal_flip=True)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        './data3',\n","        target_size=(224, 224),\n","        batch_size=12,\n","        shuffle=True,\n","        subset='training')\n","validation_generator = train_datagen.flow_from_directory(\n","        './data3',\n","        target_size=(224, 224),\n","        batch_size=12,\n","        subset='validation',\n","        shuffle=True)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 719 images belonging to 4 classes.\n","Found 179 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1enk0NS5_Vj7","colab_type":"code","colab":{}},"source":["model.fit(\n","        train_generator,\n","        steps_per_epoch = train_generator.samples // 12,\n","        epochs=120,\n","        validation_data = validation_generator,\n","        validation_steps = validation_generator.samples // 12,\n","        callbacks=callbacks_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SFx-EaH3C_tr","colab_type":"code","colab":{}},"source":["# model.evaluate_generator(train_generator)\n","model.save(\"models/Epoch120-prune.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sBH7nXTfI9tt","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing import image\n","\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","\n","model = load_model('Epoch113-loss0.020-val0.00079-updated.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTNouR6EJVEd","colab_type":"code","colab":{}},"source":["import os\n","import time\n","direction = './data3/other/'\n","c = 0\n","d =os.listdir(direction)\n","for i in d:\n","    img_path = direction + i\n","    img = image.load_img(img_path,target_size=(224,224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = x/255\n","    t1= time.time()\n","    y = model.predict(x)\n","    t2= time.time()\n","    print(t2-t1)\n","    cl = (np.argmax(y))\n","    print(y[0][cl])\n","    if np.argmax(y) != 2:\n","        c+=1\n","\n","print(c,len(d))\n","print(100*(1-c/len(d)),'%')\n","\n","#     x = tf.constant(x)\n","#     t1= time.time()\n","#     labeling = infer(x)\n","#     preds = labeling['dense_9'].numpy()\n","#     t2= time.time()\n","#     print(t2-t1)\n","#     idm = (np.argmax(preds))\n","#     print(preds[0][idm]*100)\n","#     if np.argmax(preds) != 1:\n","#         c+=1\n","# print(t2-t1)\n","# print(c,len(d))\n","# print(100*(1-c/len(d)),'%')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ucrhh5PHK60T","colab_type":"code","colab":{}},"source":["import tensorflow_model_optimization as tfmot\n","\n","prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","# Compute end step to finish pruning after 2 epochs.\n","batch_size = 12\n","epochs = 2\n","# validation_split = 0.1 # 10% of training set will be used for validation set. \n","\n","num_images = 717\n","end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n","\n","# Define model for pruning.\n","pruning_params = {\n","      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.90,\n","                                                               final_sparsity=0.90,\n","                                                               begin_step=0,\n","                                                               end_step=end_step)\n","}\n","\n","model_for_pruning = prune_low_magnitude(model, **pruning_params)\n","\n","# `prune_low_magnitude` requires a recompile.\n","model_for_pruning.compile(optimizer=model.optimizer, loss='categorical_crossentropy')\n","\n","model_for_pruning.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBa194FsEaFZ","colab_type":"code","outputId":"cc4d515c-4af7-493b-da74-b24c3b9ba60d","executionInfo":{"status":"error","timestamp":1591608038260,"user_tz":-420,"elapsed":119601,"user":{"displayName":"Hoang Manh TIEN","photoUrl":"","userId":"14223269599878818311"}},"colab":{"base_uri":"https://localhost:8080/","height":598}},"source":["import tempfile\n","logdir = tempfile.mkdtemp()\n","\n","callbacks = [\n","  tfmot.sparsity.keras.UpdatePruningStep(),\n","  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n","]\n","  \n","model_for_pruning.fit(\n","        train_generator,\n","        steps_per_epoch=train_generator.samples//12,\n","        epochs=10,\n","        validation_data=validation_generator,\n","        validation_steps=validation_generator.samples//12,\n","        callbacks=callbacks)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"," 2/59 [>.............................] - ETA: 41s - loss: 1.1987WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.646390). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.646390). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["59/59 [==============================] - 19s 330ms/step - loss: 0.7130 - val_loss: 1.6878\n","Epoch 2/10\n","59/59 [==============================] - 17s 291ms/step - loss: 0.3626 - val_loss: 2.1026\n","Epoch 3/10\n","59/59 [==============================] - 17s 289ms/step - loss: 0.2323 - val_loss: 1.8908\n","Epoch 4/10\n","59/59 [==============================] - 17s 290ms/step - loss: 0.1937 - val_loss: 1.8393\n","Epoch 5/10\n","59/59 [==============================] - 17s 290ms/step - loss: 0.1704 - val_loss: 1.7047\n","Epoch 6/10\n","12/59 [=====>........................] - ETA: 10s - loss: 0.2065"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-17704bdfa83a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         callbacks=callbacks)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m--> 847\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mtuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruning_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3382\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3384\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3385\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3386\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 848\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m    141\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AssignVariableOp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         tld.op_callbacks, resource, value)\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"GWPZaqrWKXK-","colab_type":"code","outputId":"accdc31b-df6c-40ac-a7d3-743babf543b8","executionInfo":{"status":"ok","timestamp":1591607759301,"user_tz":-420,"elapsed":198824,"user":{"displayName":"Hoang Manh TIEN","photoUrl":"","userId":"14223269599878818311"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from tensorflow.keras.models import save_model\n","model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","\n","_, pruned_keras_file = tempfile.mkstemp('.h5')\n","save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n","print('Saved pruned Keras model to:', pruned_keras_file)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved pruned Keras model to: /tmp/tmpak6yx3gc.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0lwjUpV2Nh5U","colab_type":"code","outputId":"efd24efd-d89e-44f7-d7ee-21fcc2c030f2","executionInfo":{"status":"ok","timestamp":1591608090498,"user_tz":-420,"elapsed":4821,"user":{"displayName":"Hoang Manh TIEN","photoUrl":"","userId":"14223269599878818311"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from tensorflow.lite.python.lite import TFLiteConverterV2\n","converter = TFLiteConverterV2.from_keras_model(model)\n","pruned_tflite_model = converter.convert()\n","\n","_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n","\n","with open(pruned_tflite_file, 'wb') as f:\n","  f.write(pruned_tflite_model)\n","\n","print('Saved pruned TFLite model to:', pruned_tflite_file)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved pruned TFLite model to: /tmp/tmpnznlpwgt.tflite\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m5ig7nLAKk2b","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}